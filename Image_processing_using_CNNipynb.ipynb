{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fanibuyanoluwaseyi/Mytestrepo/blob/main/Image_processing_using_CNNipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the libraries\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "R0znmLsnad9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "off2uyqKNdMV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/dogs-vs-cats-vvsmall.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "_p_mr7RaNoHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp/dogs-vs-cats-vvsmall'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "#Drectory with the train cat images\n",
        "train_cat_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "#Drectory with the train dog images\n",
        "train_dog_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "#Drectory with the validation cat images\n",
        "validation_cat_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "#Drectory with the validation dogs images\n",
        "validation_dog_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n"
      ],
      "metadata": {
        "id": "unRpxJSGOZXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the names of the first 10 files to give a nice feeling that the files are arranged as expected\n",
        "# i.e. images of horses in the horses folder and images of humans in the human folder\n",
        "train_horse_names = os.listdir(train_cat_dir)\n",
        "print(train_horse_names[:10])\n",
        "\n",
        "train_human_names = os.listdir(train_dog_dir)\n",
        "print(train_human_names[:10])\n",
        "\n",
        "validation_horse_hames = os.listdir(validation_cat_dir)\n",
        "print(validation_horse_hames[:10])\n",
        "\n",
        "validation_human_names = os.listdir(validation_dog_dir)\n",
        "print(validation_human_names[:10])"
      ],
      "metadata": {
        "id": "ZVE456wLQej0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the number of images in the directories\n",
        "print('total training cat images:', len(os.listdir(train_cat_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dog_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cat_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dog_dir)))"
      ],
      "metadata": {
        "id": "xqdeyGz5Qm4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display images from the dataset\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "# pick the first 8 cat pictures\n",
        "next_horse_pix = [os.path.join(train_cat_dir, fname)\n",
        "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
        "# pick the first 8 dog pictures\n",
        "next_human_pix = [os.path.join(train_dog_dir, fname)\n",
        "                for fname in train_human_names[pic_index-8:pic_index]]\n",
        "\n",
        "# add the horse and human pictures together in a list and plot in\n",
        "# the specified number of rows and columns\n",
        "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off')\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NaWoX23AaxdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/dogs-vs-cats-vvsmall/train',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 300x300\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/tmp/dogs-vs-cats-vvsmall/validation',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 300x300\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "mqw2tBgOa5Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Defining the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(300, 300, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(300, 300),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                              target_size=(300, 300),\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "# Learning rate scheduler\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.001\n",
        "    if epoch > 30:\n",
        "        lr *= 0.1\n",
        "    elif epoch > 20:\n",
        "        lr *= 0.5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "                    epochs=50,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
        "                    verbose=1)\n",
        "# summarize the history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize the history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XfJjfAUpAguh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLG1ZgwZOZ3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}